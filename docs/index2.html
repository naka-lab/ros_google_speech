<!DOCTYPE html>
<html>
 
<head>
    <meta charset="UTF-8">
    <title>Web Speech API</title>
    <script>
        const sleep = waitTime => new Promise( resolve => setTimeout(resolve, waitTime) ); // sleep関数
        var flag_speech = 0;
        var wSck= null;
        var is_connected = false
        var recognition = null;

        connect_websock()

        // websocketへの接続
        function connect_websock() {
            wSck= new WebSocket("ws://localhost:60000/");

            // WebSocket関連の関数
            wSck.onopen = function() {
                document.getElementById('status_connection').innerHTML += "接続完了";
                is_connected = true
            };

            wSck.onclose = function() {
                document.getElementById('status_connection').innerHTML = "接続切断．．．";
                is_connected = false
                sleep( 1000 )
                document.getElementById('status_connection').innerHTML += "再接続試行中．．．"
                connect_websock() // 接続を再試行
            };

            wSck.onmessage = function(e) {
                document.getElementById('utterance').value = e.data;
                say()
            };
        }

        // 音声認識関数
        var send_msg = function(val) {
            var line = document.getElementById('msg');
            wSck.send(line.value);
        };

        function start_sr() {
            recognition = new webkitSpeechRecognition();
            window.SpeechRecognition = window.SpeechRecognition || webkitSpeechRecognition;
            recognition.lang = 'ja';
            recognition.interimResults = true;
            recognition.continuous = true;
            recognition.maxAlternatives=10;

            recognition.onsoundstart = function() {
                document.getElementById('status_sr').innerHTML = "認識中";
            };
            recognition.onnomatch = function() {
                document.getElementById('status_sr').innerHTML = "認識失敗";
            };
            recognition.onerror = function() {
                document.getElementById('status_sr').innerHTML = "エラー";
                if(flag_speech == 0)
                start_sr();
            };
            recognition.onsoundend = function() {
                document.getElementById('status_sr').innerHTML = "停止中";
                start_sr();
            };
 
            recognition.onresult = function(event) {
                var results = event.results;
                for (var i = event.resultIndex; i < results.length; i++) {
                    if (results[i].isFinal)
                    {
                        let txt = ""
                        for(let j=0; j<results[i].length ; j++){
                            txt += results[i][j].transcript + ":" + results[i][j].confidence + "\n"
                        }
                        document.getElementById('result_text').innerHTML = txt

                        //document.getElementById('result_text').innerHTML = results[i][0].transcript + ":" + results[i][0].confidence;
                        wSck.send(txt);
                        start_sr();
                    }
                    else
                    {
                        document.getElementById('result_text').innerHTML = "[認識中...] " + results[i][0].transcript;
                        flag_speech = 1;
                    }
                }
            }
            flag_speech = 0;
            document.getElementById('status_sr').innerHTML = "start";
            recognition.start();
        }

        // 発話関数
        async function say() {
            var line = document.getElementById('utterance');
            const uttr = new SpeechSynthesisUtterance(line.value)

            uttr.lang = "ja-JP"
            uttr.rate = 1.0
            uttr.pitch = 1.0
            uttr.volume = 1.0

            console.log("aaaa")

            
            if( recognition!=null ){
                console.log("stop");
                recognition.onend = function ( event ){
                    console.log("onend");
                };
                recognition.stop();
                uttr.onend = function(event) {
                    console.log("restart");
                    recognition.start();
                };
            };

            await sleep(500);
            console.log("speak")
            speechSynthesis.speak(uttr);
        }

        function start_all(){
            // 一度ボタンから発話させないと動作しないため，発話させる
            document.getElementById('utterance').value = "音声認識を開始しました";
            start_sr()
            say()
        }
        function start_synthesis(){
            // 一度ボタンから発話させないと動作しないため，発話させる
            document.getElementById('utterance').value = "音声合成を開始しました";
            say()
        }
    </script> 
</head>
 
<body>
    <input type="button" onClick="start_all();" value="音認認識・合成開始">
    <input type="button" onClick="start_synthesis();" value="音認合成のみ開始">
    <br>
    <br>
    認識結果：<br>
    <textarea id="result_text" cols="50" rows="5"></textarea>
    <br>
    認識状態：<br>
    <textarea id="status_sr" cols="50" rows="1"></textarea>
    <br>
    接続状態：<br>
    <textarea id="status_connection" cols="50" rows="1"></textarea>
    <br>
    <br>
    送信テスト：<br>
    <textarea id="msg" cols="50" rows="1"></textarea>
    <input type="button" onClick="send_msg();" value="送信">
    <br>
    <br>
    発話：<br>
    <textarea id="utterance" cols="50" rows="1"></textarea>
    <input type="button" onClick="say();" value="発話">

</body>
 
</html>